{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "combined_approach.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fms67_9Z6ypz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "9bea66b9-0ff2-40c7-d969-6bb78befbe75"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXcw1wOW6bje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import csv\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eATxJASYLJma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# с элмо\n",
        "class Combiner:\n",
        "    def __init__(self, path, column_name):\n",
        "        self._path_to_data_dir = path\n",
        "        self._data_files = sorted(os.listdir(os.path.join(self._path_to_data_dir, 'test')))\n",
        "        self._data_ml = os.path.join(self._path_to_data_dir,'test_ml', '120_5_3_150_chars_elmo')\n",
        "        self._data_rules = os.path.join(self._path_to_data_dir, 'rules')\n",
        "        self.column_name = column_name\n",
        "\n",
        "    def combine(self):\n",
        "        # перебираем имена файлов\n",
        "        for data_file in tqdm(self._data_files, desc='Adding data'):\n",
        "            model_tags = list()\n",
        "            rules_tags = list()\n",
        "            # открываем файл с тегами, полученными моделью\n",
        "            with open(os.path.join(self._data_ml, data_file), 'r', encoding='utf-8') as data_f:\n",
        "                reader = csv.DictReader(data_f)\n",
        "                for row in reader:\n",
        "                    model_tags.append(row['predicted_ml_tag'])\n",
        "            with open(os.path.join(self._data_rules, data_file), 'r', encoding='utf-8') as data_f:\n",
        "                rules_reader = csv.DictReader(data_f)\n",
        "                # записываем результаты в новый файл\n",
        "                with open(os.path.join(self._path_to_data_dir, 'combined', data_file), 'w', encoding='utf-8', newline='') as task:\n",
        "                        fieldnames = ['token', 'tag', self.column_name]\n",
        "                        writer = csv.DictWriter(task, fieldnames=fieldnames)\n",
        "                        writer.writeheader()\n",
        "                        for i, row in enumerate(rules_reader):\n",
        "                            ml_tag = model_tags[i]     \n",
        "                            rules_tag = row['predicted_rules_tag']      \n",
        "                            gtags = ['B-DATE', 'I-DATE', 'B-DURATION', 'I-DURATION'] \n",
        "                            mtags = ['B-TIME', 'I-TIME', 'B-SET', 'I-SET']\n",
        "\n",
        "                            if rules_tag != ml_tag:\n",
        "                                if (rules_tag.endswith('SET') == True) or (ml_tag.endswith('SET')== True) :\n",
        "                                    result_tag = rules_tag\n",
        "                                else:\n",
        "                                    result_tag = ml_tag\n",
        "                                \n",
        "                                writer.writerow({'token' : row['token'], 'tag' : row['tag'], self.column_name: result_tag})  \n",
        "                            else:\n",
        "                                writer.writerow({'token' : row['token'], 'tag' : row['tag'], self.column_name: ml_tag})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd9ra7cnLTIw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6d4107c-9d3c-48a9-9f73-9ad87c51ef83"
      },
      "source": [
        "combiner = Combiner('/content/gdrive/My Drive/Mezentseva Zavarzina/experiments_dl_model/', 'predicted_combined_tag')\n",
        "combiner.combine()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adding data: 100%|██████████| 20/20 [00:00<00:00, 89.98it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYXyxoCoLTdu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# чистка от того, чтобы начальный тег был начальным"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLxpplfpueJ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "b3712e25-2327-4b3e-bc41-f7edbffdbac4"
      },
      "source": [
        "!pip install seqeval\n",
        "from seqeval.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.4)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.3.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.12.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=7cbbb27268b854505ac7d3e7cddfb8561939005278d80693f0e3dedff6822f73\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-0.0.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0802g1evughD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Evaluator:\n",
        "    \"\"\" Класс для оценки качества извлечения временных выражений \"\"\"\n",
        "\n",
        "    def __init__(self, path, column_pred):\n",
        "        self._predicted_files_dir = path\n",
        "        self._predicted_files = sorted(os.listdir(self._predicted_files_dir))\n",
        "        self.column_pred = column_pred\n",
        "\n",
        "    def evaluate(self) -> str:\n",
        "        \"\"\" Оценка качества извлечения временных выражений\n",
        "        :return: метрики: precision, recall, F-1 score для каждого класса отдельно и для всех усреднённые\n",
        "        \"\"\"\n",
        "        preds, targets = self._load_predictons()\n",
        "        report = classification_report(y_true=targets, y_pred=preds)\n",
        "        return report\n",
        "\n",
        "    def _load_predictons(self):\n",
        "        \"\"\" Загружает targets и predictions из заранее сформированных csv файлов\n",
        "        :return: predictions, targets\n",
        "        \"\"\"\n",
        "        preds = []\n",
        "        targets = []\n",
        "        for predicted_file in self._predicted_files:\n",
        "            with open(os.path.join(self._predicted_files_dir, predicted_file), 'r') as predicted_file:\n",
        "                reader = csv.DictReader(predicted_file)\n",
        "                preds_from_file = []\n",
        "                targets_from_file = []\n",
        "                for row in reader:\n",
        "                    preds_from_file.append(row[str(self.column_pred)])\n",
        "                    targets_from_file.append(row['tag'])\n",
        "                preds.append(preds_from_file)\n",
        "                targets.append(targets_from_file)\n",
        "        return preds, targets\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C4d5PELu4Ya",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "bf9f353e-c1dc-4901-9926-37174e4c1e93"
      },
      "source": [
        "evaluator = Evaluator('/content/gdrive/My Drive/Mezentseva Zavarzina/experiments_dl_model/combined', 'predicted_combined_tag')\n",
        "report = evaluator.evaluate()\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           precision    recall  f1-score   support\n",
            "\n",
            " DURATION       0.41      0.51      0.46        35\n",
            "     DATE       0.83      0.68      0.75       101\n",
            "      SET       1.00      0.25      0.40         4\n",
            "     TIME       0.50      0.25      0.33         4\n",
            "\n",
            "micro avg       0.68      0.62      0.65       144\n",
            "macro avg       0.72      0.62      0.66       144\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1ZtHuofvJQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# то, как было без элмо\n",
        "class Combiner:\n",
        "    def __init__(self, path, column_name):\n",
        "        self._path_to_data_dir = path\n",
        "        self._data_files = sorted(os.listdir(os.path.join(self._path_to_data_dir, 'test')))\n",
        "        self._data_ml = os.path.join(self._path_to_data_dir,'test_ml', '120_5_3_150_chars_elmo')\n",
        "        self._data_rules = os.path.join(self._path_to_data_dir, 'rules')\n",
        "        self.column_name = column_name\n",
        "\n",
        "    def combine(self):\n",
        "        # перебираем имена файлов\n",
        "        for data_file in tqdm(self._data_files, desc='Adding data'):\n",
        "            model_tags = list()\n",
        "            rules_tags = list()\n",
        "            # открываем файл с тегами, полученными моделью\n",
        "            with open(os.path.join(self._data_ml, data_file), 'r', encoding='utf-8') as data_f:\n",
        "                reader = csv.DictReader(data_f)\n",
        "                for row in reader:\n",
        "                    model_tags.append(row['predicted_ml_tag'])\n",
        "            with open(os.path.join(self._data_rules, data_file), 'r', encoding='utf-8') as data_f:\n",
        "                rules_reader = csv.DictReader(data_f)\n",
        "                # записываем результаты в новый файл\n",
        "                with open(os.path.join(self._path_to_data_dir, 'combined', data_file), 'w', encoding='utf-8', newline='') as task:\n",
        "                        fieldnames = ['token', 'tag', self.column_name]\n",
        "                        writer = csv.DictWriter(task, fieldnames=fieldnames)\n",
        "                        writer.writeheader()\n",
        "                        for i, row in enumerate(rules_reader):\n",
        "                            ml_tag = model_tags[i]     \n",
        "                            rules_tag = row['predicted_rules_tag']      \n",
        "                            gtags = ['B-DATE', 'I-DATE', 'B-DURATION', 'I-DURATION'] \n",
        "                            mtags = ['B-TIME', 'I-TIME', 'B-SET', 'I-SET']\n",
        "\n",
        "                            if rules_tag != ml_tag:\n",
        "                                if rules_tag in mtags:\n",
        "                                    result_tag = rules_tag\n",
        "                                elif ml_tag in mtags:\n",
        "                                    result_tag = rules_tag\n",
        "                                \n",
        "                                elif (rules_tag == 'O') and (ml_tag.endswith('DATE') == True):\n",
        "                                    result_tag = ml_tag\n",
        "                                elif (rules_tag == 'O') and (ml_tag.endswith('DATE') == False):\n",
        "                                    result_tag = rules_tag\n",
        "\n",
        "                                elif (rules_tag.endswith('DATE') == True) and (ml_tag == 'O'):\n",
        "                                    result_tag = ml_tag\n",
        "                                elif (rules_tag.endswith('DATE') == True) and (ml_tag.endswith('DURATION') == True):\n",
        "                                    result_tag = ml_tag\n",
        "                                \n",
        "                                elif (rules_tag.endswith('DURATION') == True) and (ml_tag.endswith('DATE') == True):\n",
        "                                    result_tag = ml_tag\n",
        "                                elif (rules_tag.endswith('DURATION') == True) and (ml_tag == 'O'):\n",
        "                                    result_tag = rules_tag\n",
        "                                            \n",
        "            \n",
        "\n",
        "                                writer.writerow({'token' : row['token'], 'tag' : row['tag'], self.column_name: result_tag})  \n",
        "                            else:\n",
        "                                writer.writerow({'token' : row['token'], 'tag' : row['tag'], self.column_name: ml_tag})"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}