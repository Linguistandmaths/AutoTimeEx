{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"time_extraction_chars_2_0.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"SD6bjv5OIjmi","colab_type":"text"},"source":["Подключимся к гугл-диску, чтобы получить доступ к датасету:"]},{"cell_type":"code","metadata":{"id":"_-JJ6eU83VVF","colab_type":"code","outputId":"5ce1c206-749d-4612-9354-68c856eb709c","executionInfo":{"status":"ok","timestamp":1590600404849,"user_tz":-420,"elapsed":1832,"user":{"displayName":"Анастасия Алексеевна Мезенцева","photoUrl":"","userId":"07144606596434247568"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZmiBhy51Ib50","colab_type":"text"},"source":["Установим нужные нам версии библиотек:\n","\n"]},{"cell_type":"code","metadata":{"id":"0Hbfzq-AIP1T","colab_type":"code","colab":{}},"source":["!pip install git+https://www.github.com/keras-team/keras-contrib.git\n","!pip install keras==2.2.2\n","!pip install tensorflow==1.15.0\n","!pip install keras_applications==1.0.7\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uxgVUsR9aI6c","colab_type":"text"},"source":["\n","\n","\n","\n","\n","\n","\n","Задаем пути "]},{"cell_type":"code","metadata":{"id":"4adXs1uwYhAm","colab_type":"code","colab":{}},"source":["time_dir = '/content/gdrive/My Drive/Mezentseva Zavarzina/experiments_dl_model/'\n","# имя папки, где будут результаты оценки и часть имени с весами\n","path_to_exp = '120_5_3_150_lastest'\n","result_dir = '/content/gdrive/My Drive/Mezentseva Zavarzina/experiments_dl_model/test_ml/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aZYhudC58zPC","colab_type":"code","outputId":"2ccb7bc2-6d8f-4ecc-86b6-fba21e635190","executionInfo":{"status":"error","timestamp":1590600411505,"user_tz":-420,"elapsed":710,"user":{"displayName":"Анастасия Алексеевна Мезенцева","photoUrl":"","userId":"07144606596434247568"}},"colab":{"base_uri":"https://localhost:8080/","height":321}},"source":["import csv\n","\n","import os\n","import zipfile\n","import os\n","import numpy as np\n","from tqdm import tqdm\n","import tensorflow as tf\n","import keras\n","from keras import backend as K\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Model, Input\n","from keras.layers.merge import add, concatenate\n","from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Lambda\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from keras_contrib.layers import CRF"],"execution_count":10,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-f681fc72bd15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimeDistributed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_contrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCRF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_contrib'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"markdown","metadata":{"id":"MYhQBrUeK86J","colab_type":"text"},"source":["Распакуем архив с данными:"]},{"cell_type":"code","metadata":{"id":"nSj02GY74cVd","colab_type":"code","outputId":"c9a7f0e7-9d14-44bd-c5ff-825dd84ae21d","executionInfo":{"status":"ok","timestamp":1590511860711,"user_tz":-420,"elapsed":1866,"user":{"displayName":"Анастасия Алексеевна Мезенцева","photoUrl":"","userId":"07144606596434247568"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["if 'train' in os.listdir(time_dir):\n","  print('Files are already extracted')\n","else:\n","  with zipfile.ZipFile(os.path.join(time_dir, 'train.zip'), 'r') as zip_ref:\n","      zip_ref.extractall(os.path.join(time_dir, 'train'))\n","\n","print(len(os.listdir(os.path.join(time_dir, 'train'))))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Files are already extracted\n","256\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JmNYBPS9LcJf","colab_type":"text"},"source":["Импортируем нужные нам библиотеки:"]},{"cell_type":"code","metadata":{"id":"dzt4FOeNCfTa","colab_type":"code","outputId":"0374cedd-784d-4d59-f97e-7feaedbd9c9b","executionInfo":{"status":"ok","timestamp":1590573280918,"user_tz":-420,"elapsed":8825,"user":{"displayName":"Анастасия Алексеевна Мезенцева","photoUrl":"","userId":"07144606596434247568"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["print(tf.__version__)\n","print(keras.__version__)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["1.15.0\n","2.2.2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Zl5UxAIAL3Ha","colab_type":"text"},"source":["Определим класс для загрузки наших данных:"]},{"cell_type":"code","metadata":{"id":"AeMyk7MO5ubs","colab_type":"code","colab":{}},"source":["class DatasetLoader:\n","\n","    def __init__(self, path_to_data_dir):\n","        self._path_to_data_dir = path_to_data_dir\n","        self._data_files = sorted(os.listdir(self._path_to_data_dir))\n","\n","\n","    def load_dataset(self):\n","        sentences = []\n","        for data_file in tqdm(self._data_files, desc='Loading data'):\n","            if not data_file.endswith('.csv'):\n","              continue\n","            with open(os.path.join(self._path_to_data_dir, data_file), 'r') as data_f:\n","                reader = csv.DictReader(data_f)\n","                sentence = []\n","                for row in reader:\n","                    sentence.append((row['token'], row['tag']))\n","                sentences.append(sentence)\n","        return sentences\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yErEXMp6MJ3l","colab_type":"text"},"source":["Определим класс для векторизации данных:"]},{"cell_type":"code","metadata":{"id":"zcewqi5c588E","colab_type":"code","colab":{}},"source":["class Vectorizer:\n","\n","    def __init__(self):\n","        self._max_sentence_len = 1000\n","        self._max_wordform_len = 30\n","        self._all_chars = u'qwertyuiopasdfghjklzxcvbnmQWERTYUIOPASDFGHJKLZXCVBNM,.?!:;\"«»-—1234567890'\n","        self._punct = u',.?!:;\"«»-—'\n","        self._letters = u'qwertyuiopasdfghjklzxcvbnmQWERTYUIOPASDFGHJKLZXCVBNM'\n","        self._numbers = u'1234567890'\n","        #self._len_all_chars = len(self._all_chars)\n","        self._len_all_chars = len(self._letters) + 2\n","        \n","        self._tag2id = {'O': 0, 'B-TIME': 1, 'I-TIME': 2, 'B-DATE': 3, 'I-DATE': 4, 'B-DURATION': 5, 'I-DURATION': 6,\n","                        'B-SET': 7, 'I-SET': 8}\n","    \n","    def get_len_all_chars(self):\n","      return self._len_all_chars\n","\n","    def vectorize_chars(self, sentences):\n","        X_chars = self.vectorize_chars_dataset(sentences)\n","        return X_chars\n","\n","    def vectorize_targets(self, sentences):\n","        y = [[self._tag2id[w[1]] for w in s] for s in sentences]\n","        y = pad_sequences(maxlen=self._max_sentence_len, sequences=y, padding=\"post\", value=self._tag2id[\"O\"])\n","        y = y.reshape(y.shape[0], y.shape[1], 1)\n","        return y\n","\n","    def vectorize_chars_dataset(self, sentences):\n","        X_chars = [[self._vectorize_chars_wordform(w[0]) for w in s] for s in sentences]\n","        X_chars = pad_sequences(maxlen=self._max_sentence_len, sequences=X_chars, padding=\"post\",\n","                                value=np.zeros((self._max_wordform_len, self._len_all_chars), dtype=np.int32))\n","        return X_chars\n","\n","    def _vectorize_chars_wordform(self, wordform):\n","        vector = np.zeros(self._max_wordform_len * self._len_all_chars)\n","        for i in range(len(wordform)):\n","            if i == self._max_wordform_len:\n","                break\n","            \"\"\"\n","            if wordform[i] in self._all_chars:\n","                ind = self._all_chars.index(wordform[i])\n","                vector[i * self._len_all_chars + ind] = 1.0\n","            \"\"\"\n","            # try to make 3 classes\n","            if wordform[i] in self._punct:\n","              ind = len(self._letters) + 1\n","              vector[i * self._len_all_chars + ind] = 1.0              \n","            if wordform[i] in self._letters:\n","              ind = self._letters.index(wordform[i])\n","              vector[i * self._len_all_chars + ind] = 1.0\n","            if wordform[i] in self._numbers:  \n","              ind = len(self._letters) + 2\n","              vector[i * self._len_all_chars + ind] = 1.0\n","        vector = vector.reshape((self._max_wordform_len, self._len_all_chars))\n","        return vector"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Up-mBrVpNBdj","colab_type":"text"},"source":["Определим класс для обучения модели:"]},{"cell_type":"code","metadata":{"id":"7ihV_UTW6MYV","colab_type":"code","colab":{}},"source":["class Trainer:\n","\n","    def __init__(self):\n","        data_dir = os.path.join(time_dir, 'train')\n","        self._data_loader = DatasetLoader(data_dir)\n","        self._vectorizer = Vectorizer()\n","\n","        self._sentences = self._data_loader.load_dataset()\n","        self._val_sentences = self._sentences[-50:]\n","        self._train_samples = self._sentences[:200]\n","\n","        self._batch_size = 5\n","        self._max_len = 1000\n","        self.steps_per_epoch = len(self._train_samples)/self._batch_size\n","\n","        self._model = self._define_model()\n","\n","    def _define_model(self):\n","        input_chars = Input(shape=(self._max_len, 30, self._vectorizer.get_len_all_chars()))\n","        chars = TimeDistributed(Bidirectional(LSTM(units=150,\n","                                                   recurrent_dropout=0.5)))(input_chars)\n","\n","        crf = CRF(9, sparse_target=True)  # CRF layer\n","        out = crf(chars)  # output\n","\n","        model = Model([input_chars], out)\n","        model.summary()\n","\n","        model.compile(optimizer=\"adam\", loss=crf.loss_function, metrics=[crf.accuracy])\n","        return model\n","\n","    def _generate_train_samples(self):\n","      i = 0\n","      while True:\n","        X_chars = self._vectorizer.vectorize_chars(self._train_samples[i:i + self._batch_size])\n","        y = self._vectorizer.vectorize_targets(self._train_samples[i:i + self._batch_size])\n","        i += self._batch_size\n","        yield [np.array(X_chars)], np.array(y)\n","        if i == len(self._train_samples):\n","          i = 0\n","\n","    def _generate_val_samples(self):\n","      i = 0\n","      while True:\n","        X_chars = self._vectorizer.vectorize_chars(self._val_sentences[i:i + self._batch_size])\n","        y = self._vectorizer.vectorize_targets(self._val_sentences[i:i + self._batch_size])\n","        i += self._batch_size\n","        yield [np.array(X_chars)], np.array(y)\n","        if i == len(self._val_sentences):\n","          i = 0\n","\n","    def train(self):\n","        weights_dir = '/content/gdrive/My Drive/Mezentseva Zavarzina/experiments_dl_model/weights_nastya'\n","        if not os.path.exists(weights_dir):\n","          os.makedirs(weights_dir)\n","        weights_file = 'weights_chars_crf_' + path_to_exp + '_.h5'\n","        modelPath = os.path.join(weights_dir, weights_file)\n","        saver = ModelCheckpoint(modelPath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n","        stopper = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='auto')\n","        history = self._model.fit_generator(self._generate_train_samples(), epochs=120,\n","                            validation_data=self._generate_val_samples(), steps_per_epoch=self.steps_per_epoch, validation_steps=10,\n","                            verbose=1, callbacks=[saver, stopper])\n","        return history"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eJSQXKqA7xgl","colab_type":"code","colab":{}},"source":["trainer = Trainer()\n","trainer.train()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QmJ39h4A2WQU","colab_type":"text"},"source":["Теперь давайте попробуем найти временные выражения, используя обученную модель. Для этого напишем класс **Predictor**"]},{"cell_type":"code","metadata":{"id":"QRiid9hLpDax","colab_type":"code","colab":{}},"source":["from nltk.tokenize import WordPunctTokenizer\n","\n","\n","class Predictor:\n","\n","    def __init__(self):\n","        self._vectorizer = Vectorizer()\n","        self._trainer = Trainer()\n","        self._tokenizer = WordPunctTokenizer()\n","        self._model = self._trainer._model\n","        self._model.load_weights('/content/gdrive/My Drive/Mezentseva Zavarzina/experiments_dl_model/weights_nastya/weights_chars_crf_' + path_to_exp + '_.h5')\n","        self._tag2id = {'O': 0, 'B-TIME': 1, 'I-TIME': 2, 'B-DATE': 3, 'I-DATE': 4, 'B-DURATION': 5, 'I-DURATION': 6,\n","                        'B-SET': 7, 'I-SET': 8}\n","        self._id2tag = self._get_id2tag()\n","\n","    def _get_id2tag(self):\n","        id2tag = dict()\n","        for tag, id in self._tag2id.items():\n","            id2tag[id] = tag\n","        return id2tag\n","\n","    def _process_input_sentence(self, sentence):\n","        tokens = self._tokenizer.tokenize(sentence)\n","        tokens_to_process = [(token, 'O') for token in tokens]\n","        input_tokens = []\n","        for i in range(20):\n","            input_tokens.append(tokens_to_process)\n","        X_chars = self._vectorizer.vectorize_chars(sentences=input_tokens)\n","        return X_chars, tokens\n","\n","    def predict(self, text):\n","        X_chars, tokens = self._process_input_sentence(text)\n","        predicts = self._model.predict([X_chars])[0]\n","        result = []\n","        for i, token in enumerate(tokens):\n","            tag = self._id2tag[np.argmax(predicts[i])]\n","            result.append((token, tag))\n","        return result\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PMNqOVNvp4S1","colab_type":"code","outputId":"b265ca77-17c9-464e-d546-404c6743a95e","executionInfo":{"status":"ok","timestamp":1590573289690,"user_tz":-420,"elapsed":5116,"user":{"displayName":"Анастасия Алексеевна Мезенцева","photoUrl":"","userId":"07144606596434247568"}},"colab":{"base_uri":"https://localhost:8080/","height":785}},"source":["predictor = Predictor()"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Loading data: 100%|██████████| 256/256 [00:00<00:00, 372.16it/s]"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:72: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:515: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4048: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:131: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3368: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         (None, 1000, 30, 54)      0         \n","_________________________________________________________________\n","time_distributed_1 (TimeDist (None, 1000, 300)         246000    \n","_________________________________________________________________\n","crf_1 (CRF)                  (None, 1000, 9)           2808      \n","=================================================================\n","Total params: 248,808\n","Trainable params: 248,808\n","Non-trainable params: 0\n","_________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:782: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_ops.py:2509: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n","  warnings.warn('CRF.loss_function is deprecated '\n","/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n","  warnings.warn('CRF.accuracy is deprecated and it '\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:172: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:179: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:184: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:188: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:204: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zAx_mcUtqAcg","colab_type":"code","outputId":"e5e139ad-79d1-47de-cdf0-c4208d1e04b1","executionInfo":{"status":"ok","timestamp":1590573295085,"user_tz":-420,"elapsed":3803,"user":{"displayName":"Анастасия Алексеевна Мезенцева","photoUrl":"","userId":"07144606596434247568"}},"colab":{"base_uri":"https://localhost:8080/","height":98}},"source":["text = 'he was born in 1994'\n","result = predictor.predict(text)\n","for r in result:\n","    print(r)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["('he', 'O')\n","('was', 'O')\n","('born', 'O')\n","('in', 'O')\n","('1994', 'B-DATE')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LE5a78EHaBbS","colab_type":"text"},"source":["Разметка тестового датасета,  получение метрик"]},{"cell_type":"code","metadata":{"id":"iT8BW4jRhDaj","colab_type":"code","colab":{}},"source":["class Labeler:\n","\n","  def __init__(self, path_to_data_dir):\n","        self._path_to_data_dir = path_to_data_dir\n","        self._data_files = sorted(os.listdir(self._path_to_data_dir))\n","\n"," \n"," \n","  def label_dataset(self, column_name):\n","        \"\"\"\n","        функция, которая записывает новую информацию в датасет\n","        :param column_name: имя столбца\n","        \"\"\"\n","        for data_file in tqdm(self._data_files, desc='Adding data'):\n","            path_to_test_file = os.path.join(self._path_to_data_dir, data_file)\n","            print(1)\n","            with open(path_to_test_file, 'r') as data_f:\n","                reader = csv.DictReader(data_f)\n","                print(2)\n","                test_dir = result_dir + path_to_exp\n","                with open(os.path.join(test_dir, data_file), 'w', encoding='utf-8', newline='') as task:\n","                    print('ok')                  \n","                    fieldnames = ['token', 'tag', column_name]\n","                    writer = csv.DictWriter(task, fieldnames=fieldnames)\n","                    writer.writeheader()\n","                    predictions = list() \n","                    data = list()\n","                    sentence = list()\n","                    for row in reader:\n","                      data.append((row['token'], row['tag']))\n","                      sentence.append(row['token'])\n","                    predictions = predictor.predict(' '.join(sentence))\n","                    for i, elem in enumerate(predictions):\n","                      token, tag = data[i]\n","                      token, pred_tag = elem \n","                      writer.writerow({'token' : token, 'tag' : tag, column_name: pred_tag})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HE2ebYfTa3df","colab_type":"code","colab":{}},"source":["ml_label = Labeler(os.path.join(time_dir, 'test'))\n","tag = 'predicted_ml_tag'\n","ml_label.label_dataset(tag)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vnCFGv-nYrDa","colab_type":"code","outputId":"57b1b86f-9c94-4dd9-dddd-33e15a1a90a0","executionInfo":{"status":"ok","timestamp":1590600483512,"user_tz":-420,"elapsed":5315,"user":{"displayName":"Анастасия Алексеевна Мезенцева","photoUrl":"","userId":"07144606596434247568"}},"colab":{"base_uri":"https://localhost:8080/","height":163}},"source":["!pip install seqeval\n","from seqeval.metrics import classification_report"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: seqeval in /usr/local/lib/python3.6/dist-packages (0.0.12)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.4)\n","Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval) (2.3.1)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.0.8)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (3.13)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.12.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.1.2)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (1.4.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval) (2.10.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"czfRqLBIU-eS","colab_type":"code","colab":{}},"source":["class Evaluator:\n","    \"\"\" Класс для оценки качества извлечения временных выражений \"\"\"\n","\n","    def __init__(self, path, column_pred):\n","        self._predicted_files_dir = path\n","        self._predicted_files = sorted(os.listdir(self._predicted_files_dir))\n","        self.column_pred = column_pred\n","\n","    def evaluate(self) -> str:\n","        \"\"\" Оценка качества извлечения временных выражений\n","        :return: метрики: precision, recall, F-1 score для каждого класса отдельно и для всех усреднённые\n","        \"\"\"\n","        preds, targets = self._load_predictons()\n","        report = classification_report(y_true=targets, y_pred=preds)\n","        return report\n","\n","    def _load_predictons(self):\n","        \"\"\" Загружает targets и predictions из заранее сформированных csv файлов\n","        :return: predictions, targets\n","        \"\"\"\n","        preds = []\n","        targets = []\n","        for predicted_file in self._predicted_files:\n","            with open(os.path.join(self._predicted_files_dir, predicted_file), 'r') as predicted_file:\n","                reader = csv.DictReader(predicted_file)\n","                preds_from_file = []\n","                targets_from_file = []\n","                for row in reader:\n","                    preds_from_file.append(row[str(self.column_pred)])\n","                    targets_from_file.append(row['tag'])\n","                preds.append(preds_from_file)\n","                targets.append(targets_from_file)\n","        return preds, targets\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"65qSzBkmZkGP","colab_type":"code","outputId":"2fa7911e-1a8d-4cfb-bcd6-770302781528","executionInfo":{"status":"ok","timestamp":1590603168351,"user_tz":-420,"elapsed":5769,"user":{"displayName":"Анастасия Алексеевна Мезенцева","photoUrl":"","userId":"07144606596434247568"}},"colab":{"base_uri":"https://localhost:8080/","height":180}},"source":["evaluator = Evaluator('/content/gdrive/My Drive/Mezentseva Zavarzina/experiments_dl_model/combined', 'predicted_combined_tag')\n","report = evaluator.evaluate()\n","print(report)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["           precision    recall  f1-score   support\n","\n"," DURATION       0.58      0.20      0.30        35\n","     DATE       0.75      0.78      0.76       101\n","     TIME       0.50      0.25      0.33         4\n","      SET       1.00      0.25      0.40         4\n","\n","micro avg       0.73      0.61      0.66       144\n","macro avg       0.71      0.61      0.63       144\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BtQhlTbVQC5X","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}